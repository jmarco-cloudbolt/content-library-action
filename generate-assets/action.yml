name: 'Generate Content Library Assets'

description: 'Generates and uploads content library assets the specified content type.'

inputs:
  content-type:
    description: 'The content type (e.g. "blueprints") to collect and upload as a .tar.gz artifact.'
    required: true
outputs:
  have-content:
    description: 'If "true" then content was found and assets were uploaded.'
    value: ${{ steps.check.outputs.have-content }}

runs:
  using: "composite"
  steps:
    - name: Prepare Environment
      id: environment
      shell: bash -leo pipefail {0}
      run: |
        echo "PREPARING ENVIRONMENT"
        echo "====================="
        MINIMUM_VERSION="9.4.6.1"
        rm -rf .[^.]* * 
        types=()
        types+=("blueprints")
        types+=("ui-extension-packages")
        types+=("orchestration-packages")
        types+=("recurring-jobs")
        types+=("server-actions")
        types+=("resource-actions")
        content_type_valid="false"
        for valid_type in ${types[@]} ; do
          if [ "${valid_type}" == "${{inputs.content-type}}" ] ; then
            content_type_valid="true"
            break
          fi
        done
        if [ "${content_type_valid}" == "false" ] ; then
            echo "Error: Content Type Not Supported." >&2
            echo "Error: Valid Content Types: ${types[@]}" >&2
            exit 1
        fi
        echo "::set-output name=minimum-version::$MINIMUM_VERSION"

    - name: Download Artifacts Message
      shell: bash -leo pipefail {0}
      run: |
        echo "DOWNLOADING ARTIFACTS"
        echo "====================="

    - name: Download All Artifacts
      uses: actions/download-artifact@v2
      with:
        path: downloads

    - name: Check If Artifact Found
      id: check
      shell: bash -leo pipefail {0}
      run: |
        echo "CHECKING FOR DOWLOADED ARTIFACTS"
        echo "================================"
        echo "Current directory"
        pwd
        echo "Tree from pwd"
        tree
        if [ -f "downloads/${{inputs.content-type}}/tmp/${{inputs.content-type}}.tar.gz" ] ; then
          echo "Content found for: ${{ inputs.content-type }}"
          echo "::set-output name=have-content::true"
        else
          echo "No artifact downloaded."
          echo "::set-output name=have-content::false"
        fi

    - name: Generate Content Library Assets
      if: ${{ steps.check.outputs.have-content == 'true' }}
      shell: bash -leo pipefail {0}
      run: |
        echo "UNTAR ALL ARTIFACT ZIP FILES"
        echo "============================"
        rm -f *.zip
        echo "current dir:"
        pwd
        cd downloads/${{inputs.content-type}}/tmp/
        echo "Untarring ${{ inputs.content-type }}.tar.gz"
        tar -xvzf "${{ inputs.content-type }}.tar.gz"
        cd ../../../

        echo "PRINT DIRECTORY TREE"
        echo "===================="
        tree

        echo "GENERATE SHA FILE FOR ARTIFACT ZIP FILES"
        echo "========================================"
        for f in downloads/${{inputs.content-type}}/tmp/*.zip; do
          echo "Generating SHA for $f"
          sha256sum "$f" >> sha256sum.txt
        done
        cat ./sha256sum.txt

        echo "GENERATE CONTENT LIBRARY ASSETS FROM ARTIFACT ZIP FILES"
        echo "======================================================="
        # WARNING: This script will skip collections with special characters in their name.
        set -x

        function set_variable {
          local varname="$1"
          local value="$2"
          local default="$3"
          # if value is empty, set it to default value
          if [ -z "$value" ]; then
            value="$default"
          fi
          printf -v "$varname" '%s' "$value"
          echo "Setting $varname to $value"
        }

        function find_sha_in_file {
          local SHAFILE="$1"
          local BASENAME="$2"
          local SHA_VAR="$3"
          set_variable "$SHA_VAR" "$(grep <"$SHAFILE" "$BASENAME" | tail -n 1 | awk '{print $1}')"
        }

        get_version() {
          set_variable "VERSION" "$(jq <"$METADATA_PATH" -r '.minimum_version')"
        }

        set_minimum_version_in_metadata() {
          local VERSION="$1"
          local MIN_VERSION="$2"
          jq --arg version "$VERSION" '.minimum_version = $version' "$METADATA_PATH" > "$METADATA_PATH.tmp"
          mv "$METADATA_PATH.tmp" "$METADATA_PATH"
        }

        add_artifact_path_to_metadata() {
          local METADATA_PATH="$1"
          local ARTIFACT_PATH="$2"
          local SHA="$3"
          cat "$METADATA_PATH" | jq .
          cat "$METADATA_PATH" | jq --arg artifactpath "$ARTIFACT_PATH" \
            --arg sha "$SHA" '. + {"artifact_path": $artifactpath } + {"sha": $sha }' >"$METADATA_PATH.tmp"
          mv "$METADATA_PATH.tmp" "$METADATA_PATH"
        }

        add_image_path_to_metadata() {
          local METADATA_PATH="$1"
          local IMAGE_PATH="$2"
          echo "$IMAGE_PATH"
          cat "$METADATA_PATH" | jq .
          cat "$METADATA_PATH" | jq --arg imagepath "$IMAGE_PATH" '. + {"library-image-url": $imagepath }' >"$METADATA_PATH.tmp"
          mv "$METADATA_PATH.tmp" "$METADATA_PATH"
        }

        add_collection_type_to_metadata() {
          local METADATA_PATH="$1"
          local COLLECTION_TYPE="$2"
          jq . "$METADATA_PATH"
          cat "$METADATA_PATH" | jq --arg collectiontype "$COLLECTION_TYPE" '. + {"collection_type": $collectiontype }' >"$METADATA_PATH.tmp"
          mv "$METADATA_PATH.tmp" "./$METADATA_PATH"
        }

        log_json() {
          local JSON="$1"
          cat "$JSON" | jq -r '.'
        }

        move_and_log_file() {
          local SRC="$1"
          local DST="$2"
          mkdir -p "$(dirname "$DST")"
          mv "$SRC" "$DST"
          echo "Moved $SRC to $DST"
        }

        extract_icon_from_zip() {
          local ZIP="$1"
          local METADATA_PATH="$2"
          cat "$METADATA_PATH"
          local ICON=$(jq -r ".icon" "$METADATA_PATH")
          mkdir -p "./tmp_images"
          echo "ICON: $ICON"
          unzip -j "$ZIP" -d "./tmp_images"
          ls ./tmp_images
          local ICON_SHA=$(sha256sum "./tmp_images/$ICON" | awk '{print $1}')
          local EXTENSION="${ICON##*.}"
          mkdir -p "./images"
          set_variable "ICON_FILENAME" "$ICON_SHA.$EXTENSION"
          echo "ICON_FILENAME: $ICON_FILENAME"
          mv ./tmp_images/"$ICON" ./images/"$ICON_FILENAME"
          rm -rf ./tmp_images
        }

        extract_metadata_from_zip() {
          local ZIP="$1"
          local DST="$2"
          local COLLECTION_NAME="$3"
          mkdir -p "$(dirname "$DST")"
          unzip -p "$ZIP" "*.json" >"$DST"
          echo "Extracted Metadata from $ZIP to $DST"
        }

        for f in downloads/${{inputs.content-type}}/tmp/*.zip; do
          echo "Processing $f ..."
          set_variable "ZIPFILE" "$f"
          set_variable "BASENAME" "$(basename "$ZIPFILE")"
          find_sha_in_file "sha256sum.txt" "$BASENAME" "SHA"
          set_variable "COLLECTION_PATH" "${ZIPFILE%.*}"
          set_variable "COLLECTION_NAME" "${BASENAME%.*}"
          extract_metadata_from_zip "$ZIPFILE" "metadata/$COLLECTION_NAME Metadata.json" "$COLLECTION_NAME"
          set_variable "METADATA_PATH" "metadata/$COLLECTION_NAME Metadata.json"
          set_variable "METADATA_FILENAME" "$(basename "$METADATA_PATH")"
          extract_icon_from_zip "$ZIPFILE" "$METADATA_PATH"
          set_variable "ARTIFACT_PATH" "zip/$SHA.zip"
          add_artifact_path_to_metadata "$METADATA_PATH" "$ARTIFACT_PATH" "$SHA"
          add_image_path_to_metadata "$METADATA_PATH" "images/$ICON_FILENAME"
          log_json "$METADATA_PATH"
          add_collection_type_to_metadata "$METADATA_PATH" "${{inputs.content-type}}"
          set_variable "VERSION" "${{steps.environment.outputs.minimum-version}}"
          set_minimum_version_in_metadata "$VERSION" "${{steps.environment.outputs.minimum-version}}"
          move_and_log_file "$ZIPFILE" "./zip/${SHA}.zip"
          move_and_log_file "$METADATA_PATH" "./$VERSION/${METADATA_FILENAME}"
        done

        echo "CLEAN UP FILES AND DIRECTORIES"
        echo "=============================="
        rm -vrf tmp
        rm -vrf CMP
        rm -vrf metadata
        rm -vrf OneFuse
        rm -vrf downloads
        rm -vrf sha256sum.txt
        rm -vrf sha256sum_png.txt

        echo "CREATE JSON FILE FOR CONTENT TYPE"
        echo "================================="
        for f in ./*/*.json; do
          echo "Processing $f ..."
          DIRNAME="$(dirname "$f")"
          # awk print last directory
          LAST_DIRNAME="$(awk -F/ '{print $NF}' <<<"$DIRNAME")"
          jq -n '[inputs]' ./$LAST_DIRNAME/*.json > "$LAST_DIRNAME/${{inputs.content-type}}".json
        done

        echo "DISPLAY DIRECTORY TREE"
        echo "======================"
        tree -L 5

        echo "CLEAN UP METADATA JSON FILES"
        echo "============================"
        find . -type f -name '*Metadata.json' -exec rm -vf {} \;

        echo "DISPLAY DIRECTORY TREE"
        echo "======================"
        tree -L 5

        echo "CREATE ASSETS TAR FILE"
        echo "======================"
        tar --exclude-vcs --ignore-failed-read -czvf assets.tar.gz *

    - name: No Assets To Upload Message
      if: ${{ steps.check.outputs.have-content == 'false'}}
      shell: bash -leo pipefail {0}
      run: |
        echo "NO ASSETS TO UPLOAD"
        echo "==================="

    - name: Uploading Assets Message
      if: ${{ steps.check.outputs.have-content == 'true'}}
      shell: bash -leo pipefail {0}
      run: |
        echo "UPLOADING ASSETS"
        echo "================"

    - name: Upload Assets
      uses: actions/upload-artifact@v2
      if: ${{ steps.check.outputs.have-content == 'true' }}
      with:
        name: ${{ inputs.content-type }} Assets
        path: |
          **/*.tar.gz

